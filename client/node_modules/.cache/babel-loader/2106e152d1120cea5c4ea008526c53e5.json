{"ast":null,"code":"//\n// FileReader\n//\n// http://www.w3.org/TR/FileAPI/#dfn-filereader\n// https://developer.mozilla.org/en/DOM/FileReader\n(function () {\n  \"use strict\";\n\n  var fs = require(\"fs\"),\n      EventEmitter = require(\"events\").EventEmitter;\n\n  function doop(fn, args, context) {\n    if ('function' === typeof fn) {\n      fn.apply(context, args);\n    }\n  }\n\n  function toDataUrl(data, type) {\n    // var data = self.result;\n    var dataUrl = 'data:';\n\n    if (type) {\n      dataUrl += type + ';';\n    }\n\n    if (/text/i.test(type)) {\n      dataUrl += 'charset=utf-8,';\n      dataUrl += data.toString('utf8');\n    } else {\n      dataUrl += 'base64,';\n      dataUrl += data.toString('base64');\n    }\n\n    return dataUrl;\n  }\n\n  function mapDataToFormat(file, data, format, encoding) {\n    // var data = self.result;\n    switch (format) {\n      case 'buffer':\n        return data;\n        break;\n\n      case 'binary':\n        return data.toString('binary');\n        break;\n\n      case 'dataUrl':\n        return toDataUrl(data, file.type);\n        break;\n\n      case 'text':\n        return data.toString(encoding || 'utf8');\n        break;\n    }\n  }\n\n  function FileReader() {\n    var self = this,\n        emitter = new EventEmitter(),\n        file;\n\n    require('bufferjs/concat');\n\n    self.addEventListener = function (on, callback) {\n      emitter.on(on, callback);\n    };\n\n    self.removeEventListener = function (callback) {\n      emitter.removeListener(callback);\n    };\n\n    self.dispatchEvent = function (on) {\n      emitter.emit(on);\n    };\n\n    self.EMPTY = 0;\n    self.LOADING = 1;\n    self.DONE = 2;\n    self.error = undefined; // Read only\n\n    self.readyState = self.EMPTY; // Read only\n\n    self.result = undefined; // Road only\n    // non-standard\n\n    self.on = function () {\n      emitter.on.apply(emitter, arguments);\n    };\n\n    self.nodeChunkedEncoding = false;\n\n    self.setNodeChunkedEncoding = function (val) {\n      self.nodeChunkedEncoding = val;\n    }; // end non-standard\n    // Whatever the file object is, turn it into a Node.JS File.Stream\n\n\n    function createFileStream() {\n      var stream = new EventEmitter(),\n          chunked = self.nodeChunkedEncoding; // attempt to make the length computable\n\n      if (!file.size && chunked && file.path) {\n        fs.stat(file.path, function (err, stat) {\n          file.size = stat.size;\n          file.lastModifiedDate = stat.mtime;\n        });\n      } // The stream exists, do nothing more\n\n\n      if (file.stream) {\n        return;\n      } // Create a read stream from a buffer\n\n\n      if (file.buffer) {\n        process.nextTick(function () {\n          stream.emit('data', file.buffer);\n          stream.emit('end');\n        });\n        file.stream = stream;\n        return;\n      } // Create a read stream from a file\n\n\n      if (file.path) {\n        // TODO url\n        if (!chunked) {\n          fs.readFile(file.path, function (err, data) {\n            if (err) {\n              stream.emit('error', err);\n            }\n\n            if (data) {\n              stream.emit('data', data);\n              stream.emit('end');\n            }\n          });\n          file.stream = stream;\n          return;\n        } // TODO don't duplicate this code here,\n        // expose a method in File instead\n\n\n        file.stream = fs.createReadStream(file.path);\n      }\n    } // before any other listeners are added\n\n\n    emitter.on('abort', function () {\n      self.readyState = self.DONE;\n    }); // Map `error`, `progress`, `load`, and `loadend`\n\n    function mapStreamToEmitter(format, encoding) {\n      var stream = file.stream,\n          buffers = [],\n          chunked = self.nodeChunkedEncoding;\n      buffers.dataLength = 0;\n      stream.on('error', function (err) {\n        if (self.DONE === self.readyState) {\n          return;\n        }\n\n        self.readyState = self.DONE;\n        self.error = err;\n        emitter.emit('error', err);\n      });\n      stream.on('data', function (data) {\n        if (self.DONE === self.readyState) {\n          return;\n        }\n\n        buffers.dataLength += data.length;\n        buffers.push(data);\n        emitter.emit('progress', {\n          // fs.stat will probably complete before this\n          // but possibly it will not, hence the check\n          lengthComputable: !isNaN(file.size) ? true : false,\n          loaded: buffers.dataLength,\n          total: file.size\n        });\n        emitter.emit('data', data);\n      });\n      stream.on('end', function () {\n        if (self.DONE === self.readyState) {\n          return;\n        }\n\n        var data;\n\n        if (buffers.length > 1) {\n          data = Buffer.concat(buffers);\n        } else {\n          data = buffers[0];\n        }\n\n        self.readyState = self.DONE;\n        self.result = mapDataToFormat(file, data, format, encoding);\n        emitter.emit('load', {\n          target: {\n            // non-standard\n            nodeBufferResult: data,\n            result: self.result\n          }\n        });\n        emitter.emit('loadend');\n      });\n    } // Abort is overwritten by readAsXyz\n\n\n    self.abort = function () {\n      if (self.readState == self.DONE) {\n        return;\n      }\n\n      self.readyState = self.DONE;\n      emitter.emit('abort');\n    }; // \n\n\n    function mapUserEvents() {\n      emitter.on('start', function () {\n        doop(self.onloadstart, arguments);\n      });\n      emitter.on('progress', function () {\n        doop(self.onprogress, arguments);\n      });\n      emitter.on('error', function (err) {\n        // TODO translate to FileError\n        if (self.onerror) {\n          self.onerror(err);\n        } else {\n          if (!emitter.listeners.error || !emitter.listeners.error.length) {\n            throw err;\n          }\n        }\n      });\n      emitter.on('load', function () {\n        doop(self.onload, arguments);\n      });\n      emitter.on('end', function () {\n        doop(self.onloadend, arguments);\n      });\n      emitter.on('abort', function () {\n        doop(self.onabort, arguments);\n      });\n    }\n\n    function readFile(_file, format, encoding) {\n      file = _file;\n\n      if (!file || !file.name || !(file.path || file.stream || file.buffer)) {\n        throw new Error(\"cannot read as File: \" + JSON.stringify(file));\n      }\n\n      if (0 !== self.readyState) {\n        console.log(\"already loading, request to change format ignored\");\n        return;\n      } // 'process.nextTick' does not ensure order, (i.e. an fs.stat queued later may return faster)\n      // but `onloadstart` must come before the first `data` event and must be asynchronous.\n      // Hence we waste a single tick waiting\n\n\n      process.nextTick(function () {\n        self.readyState = self.LOADING;\n        emitter.emit('loadstart');\n        createFileStream();\n        mapStreamToEmitter(format, encoding);\n        mapUserEvents();\n      });\n    }\n\n    self.readAsArrayBuffer = function (file) {\n      readFile(file, 'buffer');\n    };\n\n    self.readAsBinaryString = function (file) {\n      readFile(file, 'binary');\n    };\n\n    self.readAsDataURL = function (file) {\n      readFile(file, 'dataUrl');\n    };\n\n    self.readAsText = function (file, encoding) {\n      readFile(file, 'text', encoding);\n    };\n  }\n\n  module.exports = FileReader;\n})();","map":null,"metadata":{},"sourceType":"script"}